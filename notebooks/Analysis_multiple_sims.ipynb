{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import editdistance\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make analysis graphs for consistency/independence/robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sequence_per_batch(data):\n",
    "    top_per_batch=[]\n",
    "    for i in data.batch.unique():\n",
    "        sub_data=data[data.batch==i] #must also group by model type and landscape id\n",
    "        #print (sub_data.true_score.max())\n",
    "        top_per_batch.append(sub_data.true_score.max())\n",
    "    return (top_per_batch)\n",
    "\n",
    "def compute_cumulative_outcomes(data): \n",
    "    outcomes=pd.DataFrame(columns=[\"landscape_id\",\"start_id\",\"model_type\",\"explorer_type\",\n",
    "                                   \"batch\",\"max_fitness\",\"cum_max_fitness\"])\n",
    "    for landscape in data.landscape_id.unique():\n",
    "        if landscape==str(-1): #or start_id==str(-1):\n",
    "            continue\n",
    "        print(landscape)\n",
    "        valid_start_ids=[x for x in data.start_id.unique()]# if landscape[landscape.index(\"L\"): landscape.index(\"R\")] in x]\n",
    "        for start_id in valid_start_ids:\n",
    "            for explorer_type in data.explorer_type.unique():\n",
    "                sub_data = data[(data.landscape_id==landscape)&\\\n",
    "                               (data.start_id==start_id)&\\\n",
    "                               (data.explorer_type==explorer_type)] \n",
    "                cum_fit=0\n",
    "                for batch, max_fitness in enumerate(get_top_sequence_per_batch(sub_data)):\n",
    "                    if max_fitness>cum_fit:\n",
    "                       cum_fit = max_fitness \n",
    "                    outcomes = outcomes.append(pd.DataFrame.from_records([{\"landscape_id\":landscape,\\\n",
    "                                          \"start_id\":start_id,\\\n",
    "                                          \"explorer_type\": explorer_type,\\\n",
    "                                          \"batch\": batch+1, \\\n",
    "                                          \"max_fitness\": max_fitness,\\\n",
    "                                          \"cum_max_fitness\": cum_fit}])) \n",
    "                    \n",
    "    return outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"../simulations/evaluations_test_six6/consistency_robustness_independence/Greedy_mu1_tr0.05_r0.1_rho1.csv\",index_col=False)\n",
    "data2=pd.read_csv(\"../simulations/evaluations_test_six6/consistency_robustness_independence/MLWFG_mu1_r0.1_rho1_beta100.csv\",index_col=False)\n",
    "data3 = pd.read_csv(\"../simulations/eval/consistency_robustness_independence/DQN_Explorer.csv\")\n",
    "data3 = data3[(data3['landscape_id'] == 'SIX6_REF_R1')]\n",
    "data = data1.append(data2).append(data3)\n",
    "sub_data=data[(data.model_type==\"NAMb_ss0.9\") & (data.start_id == 'TF0')]\n",
    "outcomes = compute_cumulative_outcomes(sub_data)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Consistency/Robustness/Independence, TF0')\n",
    "sns.lineplot(x=\"batch\",y=\"cum_max_fitness\",hue=\"explorer_type\",data= outcomes, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"../simulations/eval/adaptivity/CMAES.csv\", index_col=False)\n",
    "data2=pd.read_csv(\"../simulations/eval/adaptivity/DQN_Explorer.csv\", index_col=False)\n",
    "data3 = pd.read_csv(\"../simulations/eval/adaptivity/DynaPPO_Agent_0.5_5_10.csv\", index_col=False)\n",
    "data4 = pd.read_csv(\"../simulations/eval/adaptivity/PPO_Agent.csv\", index_col=False)\n",
    "data = data1.append(data2).append(data3).append(data4)\n",
    "sub_data=data[(data.model_type==\"NAMb_ss0.9\") & (data.start_id == 'TF0') & (data['landscape_id'] == 'SIX6_REF_R1')]\n",
    "outcomes = compute_cumulative_outcomes(sub_data)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Adaptivity, TF0')\n",
    "sns.lineplot(x=\"batch\",y=\"cum_max_fitness\",hue=\"explorer_type\",data= outcomes, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.read_csv(\"../simulations/eval/consistency_robustness_independence/DQN_Explorer.csv\")\n",
    "data3 = data3[(data3['start_id'] == 'TF0') & (data3['landscape_id'] == 'SIX6_REF_R1') & \n",
    "              (data3['model_type'] == 'NAMb_ss0.9')]\n",
    "outcomes3 = compute_cumulative_outcomes(data3)\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.lineplot(x=\"batch\",y=\"cum_max_fitness\",hue=\"explorer_type\",data=outcomes3, color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run analysis graphs for other simulation types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sequential_edit_distances(seq_df, cutoff=0):\n",
    "    # seq_df is a dataframe with the same format as that of the output logs \n",
    "    seqs_fitnesses = seq_df[['sequence', 'true_score']]\n",
    "    seqs_fitnesses = seqs_fitnesses[seqs_fitnesses['true_score'] >= cutoff]\n",
    "    seqs_fitnesses.sort_values('true_score', ascending=False, inplace=True)\n",
    "    seqs = seqs_fitnesses['sequence'].values\n",
    "    distances = []\n",
    "    for i in range(len(seqs) - 1):\n",
    "        comp_seq = seqs[i+1]\n",
    "        top_seqs = seqs[:(i+1)]\n",
    "        distances.append([editdistance.eval(seq, comp_seq) for seq in top_seqs])\n",
    "    return distances \n",
    "\n",
    "def compute_all_edit_distances(seq_df, cutoff=0):\n",
    "    seqs = seq_df['sequence'].values\n",
    "    distances = []\n",
    "    for seq in seqs:\n",
    "        distances.append([editdistance.eval(seq, seq2) for seq2 in seqs])\n",
    "    return distances\n",
    "\n",
    "def compare_sequential_edit_distances(batches):\n",
    "    # put in dictionary consisting of explorer: batch \n",
    "    for name, batch in batches.items():\n",
    "        sequential_distances = compute_sequential_edit_distances(batch)\n",
    "        counts, bin_edges = np.histogram(list(itertools.chain.from_iterable(sequential_distances)))\n",
    "        counts = counts * 1.0 / counts.sum()\n",
    "        plt.plot(bin_edges[:-1], counts, label=name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def compare_all_edit_distances(batches):\n",
    "    # put in dictionary consisting of explorer: batch \n",
    "    for name, batch in batches.items():\n",
    "        sequential_distances = compute_all_edit_distances(batch)\n",
    "        counts, bin_edges = np.histogram(list(itertools.chain.from_iterable(sequential_distances)))\n",
    "        counts = counts * 1.0 / counts.sum()\n",
    "        plt.plot(bin_edges[:-1], counts, label=name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = {'DQN': 'DQN_efficiency.csv', \n",
    "              'Greedy': 'Greedy_mu1_tr0.05_r0.2_rho1_efficiency.csv',\n",
    "              'BO': 'BO_Efficiency.csv'}\n",
    "batches = {}\n",
    "for name, file_name in file_names.items():\n",
    "    test_data = pd.read_csv(\"../plotting_data_subset/\" + file_name)\n",
    "    batch = test_data[(test_data['batch'] == 9) \n",
    "                          & (test_data['landscape_id'] == 'B1L14RNA1') \n",
    "                          & (test_data['start_id'] == 'startRNAL14_0') \n",
    "                          & (test_data['model_type'] == 'AdaENS_3_NAMb_ss1')]\n",
    "    batches[name] = batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_sequential_edit_distances(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_all_edit_distances(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
